---
title: "k-NN Practice (Image)"
author: "Jinwoo Chung"
output: html_document
---

## Table of Contents
1. Setup
2. Separate Train and Test Data
3. Use caret::train to find the optimal k for k-NN
4. Confusion Matrix of the Result from k-NN

for more information about the dataset visit [Digit Recognizer]<https://www.kaggle.com/c/digit-recognizer>

### Setup
```{r}
library(pacman)
pacman::p_load(data.table)
# the data is around 6MB, so it takes some time to import
main <- as.data.frame(data.table::fread('https://raw.githubusercontent.com/Jinwooooo/fcdc-ml-practice/master/data/recognizer_train.csv'))
# checking if how many rows the data has
nrow(main)
```

### Separate Train and Test Data
```{r}
# setting seed
set.seed(55)
# splitting data
index.train <- sample(1:nrow(main), round(nrow(main) * 0.8))
train <- main[index.train,]
test <- main[-index.train,]
head(train)
```

### Use caret::train to find the optimal k for k-NN
```{r}
ctrl <- caret::trainControl(method='repeatedcv', repeats=3)
# default k values are from 5~9, in order to do wider range of k, need to expand the k grid
grid <- expand.grid(k=c(1,3,5,7,10,15,20,25,30))
optimal.k <- caret::train(label ~ ., data=train, method='knn', trControl=ctrl, tuneGrid = grid)
plot(optimal.k)
```

Optimal Value : k = 3

### k-NN Result and Confusion Matrix
```{r}
knn3.train <- class::knn(train=train[,-1], test=test[,-1], cl=train[,1], k=3)
caret::confusionMatrix(knn3.train, as.factor(test[,1]))
```

#### Conclusion

Judging by Accurcy : ~91.67% and Kappa : 0.9072, seems like kNN is a very good classifier ML for this data set




